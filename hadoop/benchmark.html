<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>集群配置与管理 | Hadoop</title>
    <meta name="generator" content="VuePress 1.7.1">
    
    <meta name="description" content="Hadoop 学习笔记">
    
    <link rel="preload" href="/assets/css/0.styles.bea26999.css" as="style"><link rel="preload" href="/assets/js/app.7696aff8.js" as="script"><link rel="preload" href="/assets/js/2.3c301967.js" as="script"><link rel="preload" href="/assets/js/13.17c333e6.js" as="script"><link rel="prefetch" href="/assets/js/10.239320ff.js"><link rel="prefetch" href="/assets/js/11.7aea8a94.js"><link rel="prefetch" href="/assets/js/12.a75c9a92.js"><link rel="prefetch" href="/assets/js/14.c658bd9d.js"><link rel="prefetch" href="/assets/js/15.adf41b6f.js"><link rel="prefetch" href="/assets/js/16.d09250f7.js"><link rel="prefetch" href="/assets/js/17.3a4cbbc8.js"><link rel="prefetch" href="/assets/js/18.a7d27d96.js"><link rel="prefetch" href="/assets/js/19.3f563a7b.js"><link rel="prefetch" href="/assets/js/20.cf7aaa65.js"><link rel="prefetch" href="/assets/js/21.dabe57d5.js"><link rel="prefetch" href="/assets/js/22.8c1d8730.js"><link rel="prefetch" href="/assets/js/23.b9917a11.js"><link rel="prefetch" href="/assets/js/24.095af618.js"><link rel="prefetch" href="/assets/js/25.d294f37a.js"><link rel="prefetch" href="/assets/js/26.fc764424.js"><link rel="prefetch" href="/assets/js/27.998a5d50.js"><link rel="prefetch" href="/assets/js/28.7d6e20a5.js"><link rel="prefetch" href="/assets/js/29.d2921661.js"><link rel="prefetch" href="/assets/js/3.566e47d9.js"><link rel="prefetch" href="/assets/js/4.23282b51.js"><link rel="prefetch" href="/assets/js/5.c842d990.js"><link rel="prefetch" href="/assets/js/6.ef414eb3.js"><link rel="prefetch" href="/assets/js/7.3152689a.js"><link rel="prefetch" href="/assets/js/8.530be27e.js"><link rel="prefetch" href="/assets/js/9.a4f965b7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.bea26999.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Hadoop</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/hadoop/install.html" class="nav-link">
  Hadoop
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/hadoop/install.html" class="nav-link">
  Hadoop
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>基础</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hadoop/install.html" class="sidebar-link">安装</a></li><li><a href="/hadoop/benchmark.html" aria-current="page" class="active sidebar-link">集群配置与管理</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/hadoop/benchmark.html#hdfs的nnbench测试-namenode基准-nnbench" class="sidebar-link">HDFS的NNbench测试[NameNode基准(nnbench)]:</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/hadoop/benchmark.html#使用10个mapper和5个reducer创建1000个文件" class="sidebar-link">使用10个mapper和5个reducer创建1000个文件：</a></li></ul></li><li class="sidebar-sub-header"><a href="/hadoop/benchmark.html#mrbench测试-mapreduce基准测试-mrbench" class="sidebar-link">MRbench测试[MapReduce基准测试(mrbench)]</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/hadoop/benchmark.html#使用terasort来评测hdfs" class="sidebar-link">使用TeraSort来评测HDFS</a></li></ul></li></ul></li><li><a href="/hadoop/hdfs.html" class="sidebar-link">HDFS</a></li><li><a href="/hadoop/io.html" class="sidebar-link">Hadoop I/O</a></li><li><a href="/hadoop/mapreduce.html" class="sidebar-link">MapReduce</a></li><li><a href="/hadoop/mysql.html" class="sidebar-link">MySQL</a></li><li><a href="/hadoop/sqoop.html" class="sidebar-link">Sqoop</a></li><li><a href="/hadoop/hive.html" class="sidebar-link">Hive</a></li><li><a href="/hadoop/hbase.html" class="sidebar-link">HBase</a></li><li><a href="/hadoop/pig.html" class="sidebar-link">Pig</a></li><li><a href="/hadoop/spark.html" class="sidebar-link">Spark</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="集群配置与管理"><a href="#集群配置与管理" class="header-anchor">¶</a> 集群配置与管理</h1> <p>除了正确启动和停止集群以外，我们还需要在Hadoop集群上运行基准测试。</p> <p>我们可以使用基准测试结果调整集群，以从中获得最佳性能。</p> <p>为了获得最佳结果，我们应该在未被使用过的集群上运行基准测试。</p> <p>Hadoop附带了多个基准测试，我们可以以最低的设置成本非常轻松地运行这些程序。</p> <p>基准打包在JAR文件中，我们可以通过不带任何参数的方式调用JAR文件来获得带有描述的基准列表：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-jobclient-3.2.0-test.jar
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/1.jpg" alt="1.jpg"></p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/2.jpg" alt="2.jpg"></p> <h3 id="使用testdfsio测试hdfs的i-o性能"><a href="#使用testdfsio测试hdfs的i-o性能" class="header-anchor">¶</a> 使用TestDFSIO测试HDFS的I/O性能：</h3> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar TestDFSIO
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/3.jpg" alt="3.jpg"></p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar TestDFSIO -write -nrFiles <span class="token number">3</span> -fileSize <span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar TestDFSIO -read -nrFiles <span class="token number">3</span> -fileSize <span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar TestDFSIO -clean
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="hdfs的nnbench测试-namenode基准-nnbench"><a href="#hdfs的nnbench测试-namenode基准-nnbench" class="header-anchor">¶</a> HDFS的NNbench测试[NameNode基准(nnbench)]:</h2> <p>NNBench（由nnbench调用）对于负载测试namenode硬件很有用。
NNBench可以在HDFS上创建，读取，重命名和删除文件。</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar nnbench -help
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/4.jpg" alt="4.jpg"></p> <h3 id="使用10个mapper和5个reducer创建1000个文件"><a href="#使用10个mapper和5个reducer创建1000个文件" class="header-anchor">¶</a> 使用10个mapper和5个reducer创建1000个文件：</h3> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar nnbench -operation create_write -maps <span class="token number">3</span> -reduces <span class="token number">1</span> -numberOfFiles <span class="token number">10</span> -replicationFactorPerFile <span class="token number">2</span> -readFileAfterOpen <span class="token boolean">true</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><h2 id="mrbench测试-mapreduce基准测试-mrbench"><a href="#mrbench测试-mapreduce基准测试-mrbench" class="header-anchor">¶</a> MRbench测试[MapReduce基准测试(mrbench)]</h2> <p>MRBench（使用mrbench调用）多次运行一个小的作业，以测试集群是否可以有效地处理少量的作业。</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar mrbench -help
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/5.jpg" alt="5.jpg"></p> <p>做一个小任务10次:</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-client-jobclient-3.2.0-tests.jar mrbench -numRuns <span class="token number">10</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><hr> <p>这对于将HDFS和MapReduce一起进行基准测试非常有用，因为完整的输入数据集是通过改组传输的.</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-examples-3.2.0.jar
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/6.jpg" alt="6.jpg"></p> <p>运行wordcount例子：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs -mkdir /wordcount
hadoop fs -mkdir /wordcount/input
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>将文件放到input文件夹：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs -put test.txt /wordcount/input
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>test.txt文件夹内容如下图所示：</p> <p><img src="/images/hadoop/8.jpg" alt="8.jpg"></p> <p>执行：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-examples-3.2.0.jar wordcount /wordcount/input /wordcount/output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/7.jpg" alt="7.jpg"></p> <p>查看结果：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs -cat /wordcount/output/part-r-00000
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/9.jpg" alt="9.jpg"></p> <h3 id="使用terasort来评测hdfs"><a href="#使用terasort来评测hdfs" class="header-anchor">¶</a> 使用TeraSort来评测HDFS</h3> <p>Hadoop自带一个名为<em>TeraSort</em>的MapReduce程序，该程序对输入进行全排序。由于全部输入数据集通过shuffle传输，所以TeraSort对于同时评测HDFS和MapReduce非常有用。测评分为三步：生成随机数据、执行排序和验证结果。</p> <p>执行程序：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-examples-3.2.0.jar teragen <span class="token number">10000</span> /terasort/input
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/10.jpg" alt="10.jpg"></p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-examples-3.2.0.jar terasort /terasort/input /terasort/output
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/11.jpg" alt="11.jpg"></p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop jar hadoop-mapreduce-examples-3.2.0.jar teravalidate /terasort/output /terasort/report
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/12.jpg" alt="12.jpg"></p> <h5 id="进入与退出安全模式"><a href="#进入与退出安全模式" class="header-anchor">¶</a> 进入与退出安全模式</h5> <p>查看当前的模式：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hdfs dfsadmin -safemode get
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>用户期望在执行某条命令之前namenode先退出安全模式，特别是在脚本中。使用wait选项能够达到这个目的：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hdfs dfsadmin -safemode <span class="token function">wait</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>进入安全模式：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hdfs dfsadmin -safemode enter
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>退出安全模式：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hdfs dfsadmin -safemode leave
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>文件系统检查(fsck)</p> <p>用于检查HDFS中文件的运行状况。</p> <p>该工具查找所有数据节点中缺少的块以及复制不足或过度的块。</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hdfs <span class="token function">fsck</span> /
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="/images/hadoop/13.jpg" alt="13.jpg"></p> <p>HDFS操作语句</p> <p>查看文件：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs -cat /directory/filename
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>删除文件：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs -rm -r /directory
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>创建文件夹：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs –mkdir /directory
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>将本地文件放到HDFS路径下：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs –put /localfile /hdfs/directory
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>从HDFS获取文件到本地路径下：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs –get /hdfs/directory/filename /localpath/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>将本地文件复制到HDFS路径下：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs –copyFromLocal /localfile /hdfs/directory
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>将HDFS文件复制到本地路径下：</p> <div class="language-bash line-numbers-mode"><pre class="language-bash"><code>hadoop fs –copyToLocal /hdfs/directory/filename /localpath/
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/hadoop/install.html" class="prev">
        安装
      </a></span> <span class="next"><a href="/hadoop/hdfs.html">
        HDFS
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.7696aff8.js" defer></script><script src="/assets/js/2.3c301967.js" defer></script><script src="/assets/js/13.17c333e6.js" defer></script>
  </body>
</html>
