<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Spark | Hadoop</title>
    <meta name="generator" content="VuePress 1.7.1">
    
    <meta name="description" content="Hadoop 学习笔记">
    
    <link rel="preload" href="/assets/css/0.styles.bea26999.css" as="style"><link rel="preload" href="/assets/js/app.7696aff8.js" as="script"><link rel="preload" href="/assets/js/2.3c301967.js" as="script"><link rel="preload" href="/assets/js/24.095af618.js" as="script"><link rel="preload" href="/assets/js/11.7aea8a94.js" as="script"><link rel="prefetch" href="/assets/js/10.239320ff.js"><link rel="prefetch" href="/assets/js/12.a75c9a92.js"><link rel="prefetch" href="/assets/js/13.17c333e6.js"><link rel="prefetch" href="/assets/js/14.c658bd9d.js"><link rel="prefetch" href="/assets/js/15.adf41b6f.js"><link rel="prefetch" href="/assets/js/16.d09250f7.js"><link rel="prefetch" href="/assets/js/17.3a4cbbc8.js"><link rel="prefetch" href="/assets/js/18.a7d27d96.js"><link rel="prefetch" href="/assets/js/19.3f563a7b.js"><link rel="prefetch" href="/assets/js/20.cf7aaa65.js"><link rel="prefetch" href="/assets/js/21.dabe57d5.js"><link rel="prefetch" href="/assets/js/22.8c1d8730.js"><link rel="prefetch" href="/assets/js/23.b9917a11.js"><link rel="prefetch" href="/assets/js/25.d294f37a.js"><link rel="prefetch" href="/assets/js/26.fc764424.js"><link rel="prefetch" href="/assets/js/27.998a5d50.js"><link rel="prefetch" href="/assets/js/28.7d6e20a5.js"><link rel="prefetch" href="/assets/js/29.d2921661.js"><link rel="prefetch" href="/assets/js/3.566e47d9.js"><link rel="prefetch" href="/assets/js/4.23282b51.js"><link rel="prefetch" href="/assets/js/5.c842d990.js"><link rel="prefetch" href="/assets/js/6.ef414eb3.js"><link rel="prefetch" href="/assets/js/7.3152689a.js"><link rel="prefetch" href="/assets/js/8.530be27e.js"><link rel="prefetch" href="/assets/js/9.a4f965b7.js">
    <link rel="stylesheet" href="/assets/css/0.styles.bea26999.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">Hadoop</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/hadoop/install.html" class="nav-link">
  Hadoop
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/hadoop/install.html" class="nav-link">
  Hadoop
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>基础</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/hadoop/install.html" class="sidebar-link">安装</a></li><li><a href="/hadoop/benchmark.html" class="sidebar-link">集群配置与管理</a></li><li><a href="/hadoop/hdfs.html" class="sidebar-link">HDFS</a></li><li><a href="/hadoop/io.html" class="sidebar-link">Hadoop I/O</a></li><li><a href="/hadoop/mapreduce.html" class="sidebar-link">MapReduce</a></li><li><a href="/hadoop/mysql.html" class="sidebar-link">MySQL</a></li><li><a href="/hadoop/sqoop.html" class="sidebar-link">Sqoop</a></li><li><a href="/hadoop/hive.html" class="sidebar-link">Hive</a></li><li><a href="/hadoop/hbase.html" class="sidebar-link">HBase</a></li><li><a href="/hadoop/pig.html" class="sidebar-link">Pig</a></li><li><a href="/hadoop/spark.html" aria-current="page" class="active sidebar-link">Spark</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/hadoop/spark.html#介绍" class="sidebar-link">介绍</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/hadoop/spark.html#spark的生态系统" class="sidebar-link">Spark的生态系统</a></li></ul></li><li class="sidebar-sub-header"><a href="/hadoop/spark.html#安装" class="sidebar-link">安装</a></li><li class="sidebar-sub-header"><a href="/hadoop/spark.html#实例" class="sidebar-link">实例</a></li></ul></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="spark"><a href="#spark" class="header-anchor">¶</a> Spark</h1> <h2 id="介绍"><a href="#介绍" class="header-anchor">¶</a> 介绍</h2> <p>Spark具有如下几个主要特点：</p> <ul><li>运行速度快：Spark使用先进的DAG（Directed Acyclic Graph，有向无环图）执行引擎，以支持循环数据流与内存计算，基于内存的执行速度可比Hadoop MapReduce快上百倍，基于磁盘的执行速度也能快十倍；</li> <li>容易使用：Spark支持使用Scala、Java、Python和R语言进行编程，简洁的API设计有助于用户轻松构建并行程序，并且可以通过Spark Shell进行交互式编程；</li> <li>通用性：Spark提供了完整而强大的技术栈，包括SQL查询、流式计算、机器学习和图算法组件，这些组件可以无缝整合在同一个应用中，足以应对复杂的计算；</li> <li>运行模式多样：Spark可运行于独立的集群模式中，或者运行于Hadoop中，也可运行于Amazon EC2等云环境中，并且可以访问HDFS、Cassandra、HBase、Hive等多种数据源。</li></ul> <h3 id="spark的生态系统"><a href="#spark的生态系统" class="header-anchor">¶</a> Spark的生态系统</h3> <p>主要包含了Spark Core、Spark SQL、Spark Streaming、MLLib和GraphX 等组件，各个组件的具体功能如下：</p> <ul><li>Spark Core：Spark Core包含Spark的基本功能，如内存计算、任务调度、部署模式、故障恢复、存储管理等。Spark建立在统一的抽象RDD之上，使其可以以基本一致的方式应对不同的大数据处理场景；通常所说的Apache Spark，就是指Spark Core；</li> <li>Spark SQL：Spark SQL允许开发人员直接处理RDD，同时也可查询Hive、HBase等外部数据源。Spark SQL的一个重要特点是其能够统一处理关系表和RDD，使得开发人员可以轻松地使用SQL命令进行查询，并进行更复杂的数据分析；</li> <li>Spark Streaming：Spark Streaming支持高吞吐量、可容错处理的实时流数据处理，其核心思路是将流式计算分解成一系列短小的批处理作业。Spark Streaming支持多种数据输入源，如Kafka、Flume和TCP套接字等；</li> <li>MLlib（机器学习）：MLlib提供了常用机器学习算法的实现，包括聚类、分类、回归、协同过滤等，降低了机器学习的门槛，开发人员只要具备一定的理论知识就能进行机器学习的工作；</li> <li>GraphX（图计算）：GraphX是Spark中用于图计算的API，可认为是Pregel在Spark上的重写及优化，Graphx性能良好，拥有丰富的功能和运算符，能在海量数据上自如地运行复杂的图算法。</li></ul> <h2 id="安装"><a href="#安装" class="header-anchor">¶</a> 安装</h2> <p>首先安装 Scala。</p> <p>先保存Scala 2.12.12，找到保存路径，进入该目录下:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>cd  /home/hadoop/spark
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>解压文件夹：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>tar -zxvf Scala-2.12.12.tgz
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>然后配置环境变量 <code>vim /etc/profile</code></p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token assign-left variable">SCALA_HOME</span><span class="token operator">=</span>/home/hadoop/spark/scala-2.12.12
<span class="token builtin class-name">export</span>  <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$SCALA_HOME</span>/bin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>使配置更改生效 <code>source /etc/profile</code>。</p> <p>然后测试安装是否成功：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>scala -version
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>接下来安装Spark。</p> <p>保存 spark-2.4.7-bin-without-hadoop.tgz 到/home/hadoop/spark</p> <p>并解压:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>tar -zxvf spark-2.4.7-bin-without-hadoop.tgz
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>修改环境变量：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>export SPARK_HOME=/home/hadoop/spark/spark-2.4.7
export PATH=$PATH:$SPARK_HOME/sbin
export PATH=$PATH:$SPARK_HOME/bin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>之后，进入/home/hadoop/spark/spark-2.4.7/conf目录下更改spark-env.sh文件：<code>vim spark-env.sh</code></p> <div class="language-shell line-numbers-mode"><pre class="language-shell"><code><span class="token builtin class-name">export</span> <span class="token assign-left variable">SCALA_HOME</span><span class="token operator">=</span>/home/hadoop/spark/scala-2.12.12
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/java/jdk1.8.0_202
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/home/hadoop/apps/hadoop-3.2.0
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CONF_DIR</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/etc/hadoop
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_DIST_CLASSPATH</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span>/home/hadoop/apps/hadoop-3.2.0/bin/hadoop classpath<span class="token variable">)</span></span>
<span class="token assign-left variable">SPARK_MASTER_HOST</span><span class="token operator">=</span><span class="token number">192.168</span>.188.100
<span class="token assign-left variable">SPARK_MASTER_PORT</span><span class="token operator">=</span><span class="token number">7077</span>
<span class="token assign-left variable">SPARK_LOCAL_DIRS</span><span class="token operator">=</span>/home/hadoop/spark/spark-2.4.7
<span class="token assign-left variable">SPARK_DRIVER_MEMORY</span><span class="token operator">=</span>1G
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><p>修改slaves配置文件：<code>vim slaves</code>，在文件里添加自己集群的ip（你的ip地址可能不同），如：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>192.168.188.100
192.168.188.101
192.168.188.102
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>之后将自己安装好的scala和spark分别发送给另外的虚拟机（这里只发送给了101的虚拟机，如果有别的虚拟机，重复再敲一遍命令，例如把101改成102）：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>scp scala-2.12.12 hadoop101:/home/hadoop/apps
scp spark-2.4.7 hadoop101:/home/hadoop/apps
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><h2 id="实例"><a href="#实例" class="header-anchor">¶</a> 实例</h2> <p>首先启动所有的集群：<code>start-all.sh</code></p> <p>再查看所有节点：<code>jps</code></p> <p>要想启动spark,先进入/home/hadoop/spark/spark-2.4.7/sbin目录：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>cd  /home/hadoop/spark/spark-2.4.7/sbin
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p>再启动：<code>./start-all.sh</code>
再查看节点：<code>jps</code>
再启动spark: spark-shell（退出spark是：:quit）</p> <img src="/images/hadoop/spark.png" width="100%" height="auto" loading="lazy" alt="spark" style="display:block;margin:2.2rem auto;max-width:100%;" data-v-2d939f46> <p>使用 spark可以从现有的 RDD 或数据源创建 DataFrames。作为示例，我们通过 Spark 提供的 JSON 格式的数据源文件 ./examples/src/main/resources/people.json 来进行演示，该数据源内容如下：
<img src="/images/hadoop/people.png" width="100%" height="auto" loading="lazy" alt="spark" style="display:block;margin:2.2rem auto;max-width:100%;" data-v-2d939f46>
执行如下命令导入数据源，并输出内容：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>val df=spark.read.json(&quot;file:///home/hadoop/spark/spark-2.4.7/examples/src/main/resources/people.json&quot;)
df.show()
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><img src="/images/hadoop/dfshow.png" width="100%" height="auto" loading="lazy" alt="spark" style="display:block;margin:2.2rem auto;max-width:100%;" data-v-2d939f46> <p>DataFrames 处理结构化数据的一些基本操作,只显示 &quot;name&quot; 列:</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>df.select(&quot;name&quot;).show() 
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><img src="/images/hadoop/dfselect.png" width="90%" height="auto" loading="lazy" alt="spark" style="display:block;margin:2.2rem auto;max-width:100%;" data-v-2d939f46> <p>将 &quot;age&quot; 加 1：<code>df.select(df(&quot;name&quot;), df(&quot;age&quot;) + 1).show()</code></p> <img src="/images/hadoop/dfselect2.png" width="90%" height="auto" loading="lazy" alt="spark" style="display:block;margin:2.2rem auto;max-width:100%;" data-v-2d939f46> <p>条件语句：<code>df.filter(df(&quot;age&quot;) &gt; 21).show()</code></p> <img src="/images/hadoop/dffilter.png" width="90%" height="auto" loading="lazy" alt="spark" style="display:block;margin:2.2rem auto;max-width:100%;" data-v-2d939f46> <p>group by 操作：<code>df.groupBy(&quot;age&quot;).count().show()</code></p> <img src="/images/hadoop/dfgroupby.png" width="90%" height="auto" loading="lazy" alt="spark" style="display:block;margin:2.2rem auto;max-width:100%;" data-v-2d939f46> <p>我们也可以使用 SQL 语句来进行操作：</p> <div class="language- line-numbers-mode"><pre class="language-text"><code>df.registerTempTable(&quot;people&quot;) // 将 DataFrame 注册为临时表 people
val result = sqlContext.sql(&quot;SELECT name, age FROM people WHERE age &gt;= 13 AND age &lt;= 19&quot;) // 执行 SQL 查询
result.show() // 输出结果
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/hadoop/pig.html" class="prev">
        Pig
      </a></span> <!----></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.7696aff8.js" defer></script><script src="/assets/js/2.3c301967.js" defer></script><script src="/assets/js/24.095af618.js" defer></script><script src="/assets/js/11.7aea8a94.js" defer></script>
  </body>
</html>
